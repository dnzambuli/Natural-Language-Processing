{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ffbae4-297a-4d15-864c-12e647915659",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "## Nzambuli Daniel\n",
    "## 665721\n",
    "#  Exploring Language Modeling with N-Gram Sizes and Smoothing Techniques\n",
    "## 22/09/2024\r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e5523-9514-4b9c-8ee0-752f3211d84e",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "The goal of this lab assignment is to understand how different n-gram sizes and smoothing \n",
    "techniques affect the performance of language models. You will implement n-gram models, \n",
    "apply various smoothing techniques, and evaluate their performance using a sample text \n",
    "dataset i.e. Movie Review Dataset\n",
    "[Here](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)\n",
    "\n",
    "## Background\n",
    "\n",
    "Language modeling is a crucial task in natural language processing (NLP) that involves\n",
    "predicting the next word in a sequence given the previous words. N-gram models are a\n",
    "type of statistical language model that uses the probabilities of sequences of n words\n",
    "to make predictions. Smoothing techniques are employed to handle the problem of zero\n",
    "probabilities for unseen n-grams in the training data.\n",
    "\n",
    "## Materials Needed\n",
    "\n",
    "- Python 3.x\n",
    "- Libraries: NLTK, NumPy, Pandas, Matplotlib (for visualization)\n",
    "- A text dataset e.g., a large text corpus like the Movie Review Dataset available on Kagglele. ata.\r",
    "aset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de532f7e-db38-4699-815e-aad08eb27c70",
   "metadata": {},
   "source": [
    "# Assignment Steps\n",
    "\n",
    "## Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d2896d-df1d-4637-b3ef-cbc953761c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b2e944-8fcb-4f10-947e-f01c0da2cda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "dataset.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c949760-437c-455e-a545-91626650f73b",
   "metadata": {},
   "source": [
    "# Reasons for Data Preprocessing\n",
    "A real-world data generally contains noises, missing values, and maybe in an unusable format which cannot be directly used for machine learning models.\n",
    "\n",
    "## Goal for Preprocessing\n",
    "\n",
    "1. Cleaning makes the data suitable for an ML model\n",
    "2. Increase the accuracy and efficiency of ML models\n",
    "\n",
    "## Steps\n",
    "\n",
    "- get the dataset\n",
    "- import the libraries\n",
    "- import the dataset\n",
    "- find missing data\n",
    "- encode categorical data\n",
    "- split data into training and test set\n",
    "- feature scaling\n",
    "\n",
    "## Key terms\n",
    "\n",
    "1. **Dataset** -- the collected data for a particular problem in a proper format\n",
    "2. **Comma-Separated Values** -- file used to save tabular data with comma separation\n",
    "3. **Numpy** -- mathematical operation python library, support operations on multidimensional arrays and matrices\n",
    "4. **Matplotlib** -- 2-D plotting library with a sub-library *pyplot*\n",
    "5. **Pandas** -- library for importing, managing and manipulation of datasets.\n",
    "6. **Scikit-learn** -- library for building machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13aacc4e-387f-4bb4-aef1-ae8a6213872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the missing data row and column values\n",
    "np.where(pd.isnull(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59470e93-ddde-42fb-8e87-2a53047fd5eb",
   "metadata": {},
   "source": [
    "# Display basic statistics about reviews and sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a96107e-050a-453d-8bde-6bbbf5ca3f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a64a965-acf1-4413-8086-8de86e537885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean      1309.431020\n",
       "std        989.728014\n",
       "min         32.000000\n",
       "25%        699.000000\n",
       "50%        970.000000\n",
       "75%       1590.250000\n",
       "max      13704.000000\n",
       "Name: review, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['review'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b46b8-83af-4683-bdd7-e62dc7d037fc",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "\n",
    "There are parts of this data that need to be modified\n",
    "\n",
    "1. Removing the HTML tags that were left in the reviews\n",
    "2. Convert all reviews into lowercase\n",
    "3. Remove all extra spaces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6426c86-adb3-44c4-8bd8-5de5185c8af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...  positive   \n",
       "1      A wonderful little production. <br /><br />The...  positive   \n",
       "2      I thought this was a wonderful way to spend ti...  positive   \n",
       "3      Basically there's a family where a little boy ...  negative   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative   \n",
       "49998  I'm going to have to disagree with the previou...  negative   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                            clean_review  \n",
       "0      one of the other reviewers has mentioned that ...  \n",
       "1      a wonderful little production. the filming tec...  \n",
       "2      i thought this was a wonderful way to spend ti...  \n",
       "3      basically there's a family where a little boy ...  \n",
       "4      petter mattei's \"love in the time of money\" is...  \n",
       "...                                                  ...  \n",
       "49995  i thought this movie did a down right good job...  \n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  \n",
       "49997  i am a catholic taught in parochial elementary...  \n",
       "49998  i'm going to have to disagree with the previou...  \n",
       "49999  no one expects the star trek movies to be high...  \n",
       "\n",
       "[50000 rows x 3 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_review(text):\n",
    "    text = re.sub(r'<br\\s*/>', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.lower()\n",
    "\n",
    "dataset['clean_review'] = dataset['review'].apply(clean_review)\n",
    "\n",
    "dataset.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb11c4-4b9b-4e76-992c-8a6571017563",
   "metadata": {},
   "source": [
    "There are no missing values in this dataset. \n",
    "\n",
    "Progress can be made towards \n",
    "\n",
    "# Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a08f60a-ef46-40b7-9d92-6e0b8e6ac707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...         1   \n",
       "1      A wonderful little production. <br /><br />The...         1   \n",
       "2      I thought this was a wonderful way to spend ti...         1   \n",
       "3      Basically there's a family where a little boy ...         0   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...         1   \n",
       "...                                                  ...       ...   \n",
       "49995  I thought this movie did a down right good job...         1   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...         0   \n",
       "49997  I am a Catholic taught in parochial elementary...         0   \n",
       "49998  I'm going to have to disagree with the previou...         0   \n",
       "49999  No one expects the Star Trek movies to be high...         0   \n",
       "\n",
       "                                            clean_review  \n",
       "0      one of the other reviewers has mentioned that ...  \n",
       "1      a wonderful little production. the filming tec...  \n",
       "2      i thought this was a wonderful way to spend ti...  \n",
       "3      basically there's a family where a little boy ...  \n",
       "4      petter mattei's \"love in the time of money\" is...  \n",
       "...                                                  ...  \n",
       "49995  i thought this movie did a down right good job...  \n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  \n",
       "49997  i am a catholic taught in parochial elementary...  \n",
       "49998  i'm going to have to disagree with the previou...  \n",
       "49999  no one expects the star trek movies to be high...  \n",
       "\n",
       "[50000 rows x 3 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder_x = LabelEncoder()\n",
    "dataset.iloc[:, 1]= label_encoder_x.fit_transform(dataset.iloc[:, 1])\n",
    "dataset.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c04995-abd8-40f0-bcd1-3a71c556ee41",
   "metadata": {},
   "source": [
    "The data has been encoded such that \n",
    "\n",
    "| Value| Representation|\n",
    "|:-----|-----:|\n",
    "|Positive| 1|\n",
    "|Negative| 0|\n",
    "\n",
    "\n",
    "Now \n",
    "\n",
    "# Perform Splitting of Data into Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a77b79-b919-4b53-ba88-130968cfbb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment', 'clean_review'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7b793af-c901-4314-b3c4-6bff06a9560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = np.array(dataset.iloc[:,2])\n",
    "y = np.array(dataset.iloc[:,1])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f85e3-f9e3-40b2-9bcc-c0b128df3336",
   "metadata": {},
   "source": [
    "## Parameters of train_test_split\n",
    "\n",
    "1. **x** -- the independent variable\n",
    "2. **y** -- the dependent variable\n",
    "3. **test_size** -- the proportion of the whole dataset that will be part of the training dataset\n",
    "4. **random_state** -- the seed for random selection\n",
    "\n",
    "there is no need to perform `Feature engineering`. This is because the *independent variable* is going to be used to make a corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a3bb1-b076-4af1-ac7b-918caf7668fc",
   "metadata": {},
   "source": [
    "# Create a Corpus\n",
    "\n",
    "corpuses need:\n",
    "- removing of punctuation\n",
    "- tokenizization of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66cf062e-4654-42d4-afb9-8620c32a3ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a335b3-3574-4651-94c2-bd3f73aa22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_text(text):\n",
    "    '''\n",
    "    preproc_text\n",
    "\n",
    "    A function that converts the text from regular text to tokenized text for a corpus\n",
    "\n",
    "    input:\n",
    "        text\n",
    "    output:\n",
    "        tokens\n",
    "    '''\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0663cb1a-7bf6-4393-8d06-ee31b1f730df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   review sentiment  \\\n",
       "0      the clouded yellow is a compact psychological ...         1   \n",
       "1      dvd has become the equivalent of the old late ...         0   \n",
       "2      good drama/comedy, with two good performances ...         1   \n",
       "3      not worth the video rental or the time or the ...         0   \n",
       "4      we've all been there, sitting with some friend...         0   \n",
       "...                                                  ...       ...   \n",
       "39995  shintarô katsu, best known for the zatôichi fi...         1   \n",
       "39996  this is easily one of the worst movies i have ...         0   \n",
       "39997  excellent film. suzy kendall will hold your in...         1   \n",
       "39998  simply put, the only saving grace this movie h...         0   \n",
       "39999  when i first heard about this movie, i noticed...         1   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [the, clouded, yellow, is, a, compact, psychol...  \n",
       "1      [dvd, has, become, the, equivalent, of, the, o...  \n",
       "2      [good, dramacomedy, with, two, good, performan...  \n",
       "3      [not, worth, the, video, rental, or, the, time...  \n",
       "4      [weve, all, been, there, sitting, with, some, ...  \n",
       "...                                                  ...  \n",
       "39995  [shintarô, katsu, best, known, for, the, zatôi...  \n",
       "39996  [this, is, easily, one, of, the, worst, movies...  \n",
       "39997  [excellent, film, suzy, kendall, will, hold, y...  \n",
       "39998  [simply, put, the, only, saving, grace, this, ...  \n",
       "39999  [when, i, first, heard, about, this, movie, i,...  \n",
       "\n",
       "[40000 rows x 3 columns]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame({\n",
    "    'review':x_train,\n",
    "    'sentiment': y_train})\n",
    "clean_df['tokens'] = clean_df['review'].apply(preproc_text)\n",
    "clean_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a21bc15-886b-4313-8da9-41da5806fb19",
   "metadata": {},
   "source": [
    "# Create N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3048128-857b-4c3a-8724-5d2171434078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ngram(token, no_n_gram):\n",
    "    ngrams = zip(*[token[i:] for i in range(no_n_gram)])\n",
    "    return [' '.join(ngram) for ngram in ngrams]\n",
    "\n",
    "# store n-grams\n",
    "ngram_counts = defaultdict(lambda: defaultdict(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80f81b6e-e941-47a7-b6db-a6e74f474082",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens in clean_df['tokens']:\n",
    "    for n in range(1, 4):  # Generate 1, 2, 3\n",
    "        ngrams = gen_ngram(tokens, n)\n",
    "        for ngram in ngrams:\n",
    "            ngram_counts[n][ngram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2851ff89-826a-4008-97df-49e2f588a2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
